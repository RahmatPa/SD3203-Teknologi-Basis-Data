# Three Ways of Storing and Accessing Lots of Images in Python
Dalam artikel membahas berbagai cara untuk menyimpan dan mengakses gambar dalam Python dengan jumlah yang besar.Metode penyimpanan yang dibahas mencakup penyimpanan gambar dalam file .png di disk, penggunaan basis data berbasis memori yang cepat (LMDB), dan penyimpanan dalam format data berhirarki (HDF5).
<!-- import numpy as np
import pickle
from pathlib import Path

# Path to the unzipped CIFAR data
data_dir = Path("data/cifar-10-batches-py/")

# Unpickle function provided by the CIFAR hosts
def unpickle(file):
    with open(file, "rb") as fo:
        dict = pickle.load(fo, encoding="bytes")
    return dict

images, labels = [], []
for batch in data_dir.glob("data_batch_*"):
    batch_data = unpickle(batch)
    for i, flat_im in enumerate(batch_data[b"data"]):
        im_channels = []
        # Each image is flattened, with channels in order of R, G, B
        for j in range(3):
            im_channels.append(
                flat_im[j * 1024 : (j + 1) * 1024].reshape((32, 32))
            )
        # Reconstruct the original image
        images.append(np.dstack((im_channels)))
        # Save the label
        labels.append(batch_data[b"labels"][i])

print("Loaded CIFAR-10 training set:")
print(f" - np.shape(images)     {np.shape(images)}")
print(f" - np.shape(labels)     {np.shape(labels)}") -->
Kode tersebut mengambil data dari dataset CIFAR-10 yang berisi banyak gambar yang dibagi ke dalam 10 kelas dengan masing-masing kelas berisi 6.000 gambar. Kemudian data tersebut diproses dengan menggunakan kode python yang selanjutnya  hasill dari proses tersebut adalah 50.000 gambar dengan ukuran 32x32 piksel dan memiliki 3 warna (RGB atau Red Green Blue) serta 50.000 label yang sesuai dengan gambar-gambar tersebut.

<!-- $ pip install Pillow -->
<!-- $ pip install lmdb -->
<!-- $ pip install h5py -->
pada pillow digaunakan untuk melaukan proses manupulasi gambar dengan nantinya dapat melaukan penyimpanan dan juga mengakses gambar dari disk yang efesien dengan lmdb lalu HDF5 digunakan sebagai format file untuk menyimpan data kompleks secara hierarkis.

## Storing a Single Image: A Comparative Study (Penyimpanan Satu Gambar: Studi Sebuah Perbandingan)
<!-- from pathlib import Path

disk_dir = Path("data/disk/")
lmdb_dir = Path("data/lmdb/")
hdf5_dir = Path("data/hdf5/")

disk_dir.mkdir(parents=True, exist_ok=True)
lmdb_dir.mkdir(parents=True, exist_ok=True)
hdf5_dir.mkdir(parents=True, exist_ok=True) -->
pada kode tersbeut merupakan persipan dari eksperimen yang dimana pada artikelakan membandingkan kinjerja dai berbagai jumlah filedengan menggunakan setiap gambar menjadi 100,000 atau 2 kali lipat dari lima batch CIFAR-10. pada kode tersebut membuat direktori yang berbeda untuk setiap metode penyimpanan dimana ada penyimpaan kedalam disk, penggunaan lmdb dan hdf5 lalu membuat direktori tersebut dengan exist=True untuk menghindari adanya kesalahan dalam pelaksanaan ekseprimen.
### Penyimpanan ke Disk
<!-- from PIL import Image
import csv

def store_single_disk(image, image_id, label):
    """ Stores a single image as a .png file on disk.
        Parameters:
        ---------------
        image       image array, (32, 32, 3) to be stored
        image_id    integer unique ID for image
        label       image label
    """
    Image.fromarray(image).save(disk_dir / f"{image_id}.png")

    with open(disk_dir / f"{image_id}.csv", "wt") as csvfile:
        writer = csv.writer(
            csvfile, delimiter=" ", quotechar="|", quoting=csv.QUOTE_MINIMAL
        )
        writer.writerow([label]) -->
kode ini untuk penyimpanan kedalam disk, dimana Fungsi store_single_disk menyimpan Image sebagai array gambar lalu image_id sebagai ID gambar yang unik dan label gambar sebagai parameter dan disimapn delam bentuk file.png dalam disk lalu label gambar juga disimpan dalam file.csv terpisah.
### Penyimpanan ke LMDB
<!-- class CIFAR_Image:
    def __init__(self, image, label):
        # Dimensions of image for reconstruction - not really necessary 
        # for this dataset, but some datasets may include images of 
        # varying sizes
        self.channels = image.shape[2]
        self.size = image.shape[:2]

        self.image = image.tobytes()
        self.label = label

    def get_image(self):
        """ Returns the image as a numpy array. """
        image = np.frombuffer(self.image, dtype=np.uint8)
        return image.reshape(*self.size, self.channels) -->
pada kode Kelas CIFAR_Image digunakan untuk merepresentasikan satu gambar dari dataset CIFAR-10 yang dimana objek kelas ini menyimpan gambar dan labelnya kemudian fungsi get_image() melakukan konversi data gambar ke format array numpy untuk diproses.
<!-- import lmdb
import pickle

def store_single_lmdb(image, image_id, label):
    """ Stores a single image to a LMDB.
        Parameters:
        ---------------
        image       image array, (32, 32, 3) to be stored
        image_id    integer unique ID for image
        label       image label
    """
    map_size = image.nbytes * 10

    # Create a new LMDB environment
    env = lmdb.open(str(lmdb_dir / f"single_lmdb"), map_size=map_size)

    # Start a new write transaction
    with env.begin(write=True) as txn:
        # All key-value pairs need to be strings
        value = CIFAR_Image(image, label)
        key = f"{image_id:08}"
        txn.put(key.encode("ascii"), pickle.dumps(value))
    env.close() -->
pada fungsi store_single_lmdb digunakan untuk menyimpan satu gambar ke dalam database LMDB yang dimana fungsi ini sama seperti penyimpan disk yaitu menerima tiga parameter yang sama.Dalam fungsi ini ukuran peta memori dihitung dengan image.nbytes lalu lingkungan LMDB dibuka dan data gambar beserta labelnya disimpan dalam transaksi tulis. Setiap data disimpan dengan kunci berupa ID gambar dalam format ASCII dan nilai berupa objek CIFAR_Image yang telah di-serialize menggunakan modul pickle kemduian setelah proses selesai maka transaksi dan lingkungan LMDB juga ditutup.
### Penyimpanan dengan HDF5
<!-- import h5py

def store_single_hdf5(image, image_id, label):
    """ Stores a single image to an HDF5 file.
        Parameters:
        ---------------
        image       image array, (32, 32, 3) to be stored
        image_id    integer unique ID for image
        label       image label
    """
    # Create a new HDF5 file
    file = h5py.File(hdf5_dir / f"{image_id}.h5", "w")

    # Create a dataset in the file
    dataset = file.create_dataset(
        "image", np.shape(image), h5py.h5t.STD_U8BE, data=image
    )
    meta_set = file.create_dataset(
        "meta", np.shape(label), h5py.h5t.STD_U8BE, data=label
    )
    file.close() -->
Fungsi store_single_hdf5 digunakan untuk menyimpan satu gambar ke dalam format file HDF5 dnegan paramater yang sama. selanjutnya, fungsi membuat sebuah file baru dalam format HDF5 dengan modul h5py, lalu menyiapkan dataset untuk menyimpan gambar dengan dimensi yang sesuai dan dataset lain yaitu meta untuk menyimpan label yang kemudian setelah dataset maupun data siap file ditutup untuk menyelesaikan proses.
### Eksperimen untuk Menyimpan Satu Gambar
<!-- _store_single_funcs = dict(
    disk=store_single_disk, lmdb=store_single_lmdb, hdf5=store_single_hdf5
) -->
fungsi _store_single_func merupakan dictionay untu menghubungkan string dengan fungsi oenyimapan gambar 3 metode sebelumnya.
<!-- from timeit import timeit

store_single_timings = dict()

for method in ("disk", "lmdb", "hdf5"):
    t = timeit(
        "_store_single_funcs[method](image, 0, label)",
        setup="image=images[0]; label=labels[0]",
        number=1,
        globals=globals(),
    )
    store_single_timings[method] = t
    print(f"Method: {method}, Time usage: {t}") -->
lalu store_single_timings digunakan untuk menyimpan hasil yang dicatat dalam pengukuran waktu dari 3 metode menggunakan fungsi timeit yang digunakan untuk membanidingkan kinerja dari 3 metode penyimpan gambar tersebut, yang dimana hasilnya sama sama menyimpan dengn sangat cepat tetapi dalam penggunan eori lmd lebih banak memkana emeori sedangkan hdf5 dan disk sebaliknya.
## Storing Many Images (Penyimpanan Banyak Gambar)
<!-- def store_many_disk(images, labels):
    """ Menyimpan rangkaian gambar ke disk
        Parameters:
        ---------------
        images       array gambar, (N, 32, 32, 3) yang akan disimpan
        labels       array label, (N, 1) yang akan disimpan
    """
    num_images = len(images)

    # Menyimpan semua gambar satu per satu
    for i, image in enumerate(images):
        Image.fromarray(image).save(disk_dir / f"{i}.png")

    # Menyimpan semua label ke file csv
    with open(disk_dir / f"{num_images}.csv", "w") as csvfile:
        writer = csv.writer(
            csvfile, delimiter=" ", quotechar="|", quoting=csv.QUOTE_MINIMAL
        )
        for label in labels:
            # Biasanya ini akan lebih dari satu nilai per baris
            writer.writerow([label])

def store_many_lmdb(images, labels):
    """ Menyimpan rangkaian gambar ke LMDB.
        Parameters:
        ---------------
        images       array gambar, (N, 32, 32, 3) yang akan disimpan
        labels       array label, (N, 1) yang akan disimpan
    """
    num_images = len(images)

    map_size = num_images * images[0].nbytes * 10

    # Membuat basis data LMDB baru untuk semua gambar
    env = lmdb.open(str(lmdb_dir / f"{num_images}_lmdb"), map_size=map_size)

    # Sama seperti sebelumnya â€” tetapi mari tulis semua gambar dalam satu transaksi tunggal
    with env.begin(write=True) as txn:
        for i in range(num_images):
            # Semua pasangan kunci-nilai harus berupa String
            value = CIFAR_Image(images[i], labels[i])
            key = f"{i:08}"
            txn.put(key.encode("ascii"), pickle.dumps(value))
    env.close()

def store_many_hdf5(images, labels):
    """ Menyimpan rangkaian gambar ke HDF5.
        Parameters:
        ---------------
        images       array gambar, (N, 32, 32, 3) yang akan disimpan
        labels       array label, (N, 1) yang akan disimpan
    """
    num_images = len(images)

    # Membuat file HDF5 baru
    file = h5py.File(hdf5_dir / f"{num_images}_many.h5", "w")

    # Membuat dataset dalam file
    dataset = file.create_dataset(
        "images", np.shape(images), h5py.h5t.STD_U8BE, data=images
    )
    meta_set = file.create_dataset(
        "meta", np.shape(labels), h5py.h5t.STD_U8BE, data=labels
    )
    file.close() -->
kode tersbut dilakukan penyusaina untuk banyak gambar,dimana fungsi store_many_disk digunakan untuk menyimpan setiap gambar secara individual ke dalam format file PNG dengan menggunakan modul PIL (Pillow) dan semua label juga disimpan dalam satu file CSV. lalu store_many_lmdb untuk menyimpan semua gambar ke dalam sebuah database LMDB dengan satu transaksi tunggalyang mana setiap gambar disimpan dengan menggunakan kunci unik berupa indeks gambar lalu pada store_many_hdf5 menyimpan semua gambar ke dalam sebuah file HDF5 yang dimana data gambar disimpan dalam sebuah dataset dengan nama images sementara label disimpan dalam dataset meta. Dari ketiga fungsi tersebut menerima dua parameter yaitu images yang merupakan array gambar dengan dimensi (N, 32, 32, 3) dan labels yang merupakan array label dengan dimensi (N, 1), di mana N adalah jumlah gambar yang akan disimpan.
<!-- cutoffs = [10, 100, 1000, 10000, 100000]

# Mari kita gandakan gambar kita sehingga kita memiliki 100.000
images = np.concatenate((images, images), axis=0)
labels = np.concatenate((labels, labels), axis=0)

# Pastikan Anda benar-benar memiliki 100.000 gambar dan label
print(np.shape(images))
print(np.shape(labels)) -->
kode tersbut merupakan langkah persipan dataset yang dimana list cutoffs berisi lima angka yang berbeda yaitu 10, 100, 1000, 10000, dan 100000, lalu melakuakan penggandaan gambar dan label menjadi 100.000 dengan fungsi np.concatenate.
<!-- _store_many_funcs = dict(
    disk=store_many_disk, lmdb=store_many_lmdb, hdf5=store_many_hdf5
)

from timeit import timeit

store_many_timings = {"disk": [], "lmdb": [], "hdf5": []}

for cutoff in cutoffs:
    for method in ("disk", "lmdb", "hdf5"):
        t = timeit(
            "_store_many_funcs[method](images_, labels_)",
            setup="images_=images[:cutoff]; labels_=labels[:cutoff]",
            number=1,
            globals=globals(),
        )
        store_many_timings[method].append(t)

        # Print out the method, cutoff, and elapsed time
        print(f"Method: {method}, Time usage: {t}") -->
kode tersbut merupakan pneerepan eksperimen untuk menyimpan banayk gambar, _store_many_funcs digunakan untuk menghubungkan 3 metode penyimpan dengan fungsi yang telah dibuat sebelumnya untuk 3metode tersebut lalu dilakuakn pengkurna waktu eksekusi untuk setiap metode dan setiap jumlah data yng diproses dalam cutoffs dan pada dictionary store_many_timings hasilnya dicatat.
<!-- import matplotlib.pyplot as plt

def plot_with_legend(
    x_range, y_data, legend_labels, x_label, y_label, title, log=False
):
    """ Displays a single plot with multiple datasets and matching legends.
        Parameters:
        --------------
        x_range         list of lists containing x data
        y_data          list of lists containing y values
        legend_labels   list of string legend labels
        x_label         x axis label
        y_label         y axis label
    """
    plt.style.use("seaborn-whitegrid")
    plt.figure(figsize=(10, 7))

    if len(y_data) != len(legend_labels):
        raise TypeError(
            "Error: number of data sets does not match number of labels."
        )

    all_plots = []
    for data, label in zip(y_data, legend_labels):
        if log:
            temp, = plt.loglog(x_range, data, label=label)
        else:
            temp, = plt.plot(x_range, data, label=label)
        all_plots.append(temp)

    plt.title(title)
    plt.xlabel(x_label)
    plt.ylabel(y_label)
    plt.legend(handles=all_plots)
    plt.show()

# Getting the store timings data to display
disk_x = store_many_timings["disk"]
lmdb_x = store_many_timings["lmdb"]
hdf5_x = store_many_timings["hdf5"]

plot_with_legend(
    cutoffs,
    [disk_x, lmdb_x, hdf5_x],
    ["PNG files", "LMDB", "HDF5"],
    "Number of images",
    "Seconds to store",
    "Storage time",
    log=False,
)

plot_with_legend(
    cutoffs,
    [disk_x, lmdb_x, hdf5_x],
    ["PNG files", "LMDB", "HDF5"],
    "Number of images",
    "Seconds to store",
    "Log storage time",
    log=True,
) -->
kode tersbut merupakan untuk menampilkan grafik dari hasi penyimpan banayk gambar dengan menggunakan fungsi plot_with_legend untuk emnampilak garfik dengan beberapa set data denga lengenda yang sesuai dan juga menampilkan waktu penyimpann metode dengan store_many_timings. Dari hasilnya pada grafik pertama menunjukan penyimpan normal tanpa penyesuaian dengan adanya perbedaan anatara fle.png dan lmdb atau hdf5 sedngkan pada grafik kedua pada hdf5 awalnya memliki keceptan yng lamabat dari lmbd tetapi memilii jumlah gambar yang lebih besar.
## Reading a Single Image (Membaca Satu Gambar)
<!-- def read_single_disk(image_id):
    """ Stores a single image to disk.
        Parameters:
        ---------------
        image_id    integer unique ID for image

        Returns:
        ----------
        image       image array, (32, 32, 3) to be stored
        label       associated meta data, int label
    """
    image = np.array(Image.open(disk_dir / f"{image_id}.png"))

    with open(disk_dir / f"{image_id}.csv", "r") as csvfile:
        reader = csv.reader(
            csvfile, delimiter=" ", quotechar="|", quoting=csv.QUOTE_MINIMAL
        )
        label = int(next(reader)[0])

    return image, label -->
pada kode ini fungsi read_single_disk mbaca 1 paramter yaitu image-Id lalu fungsi membuka dan membaca gambar dari file PNG dengan menggunakan modul PIL kemudian membaca label yang terkait dengan gambar tersebut dari file CSV yang sesuai. 
<!-- def read_single_lmdb(image_id):
    """ Stores a single image to LMDB.
        Parameters:
        ---------------
        image_id    integer unique ID for image

        Returns:
        ----------
        image       image array, (32, 32, 3) to be stored
        label       associated meta data, int label
    """
    # Open the LMDB environment
    env = lmdb.open(str(lmdb_dir / f"single_lmdb"), readonly=True)

    # Start a new read transaction
    with env.begin() as txn:
        # Encode the key the same way as we stored it
        data = txn.get(f"{image_id:08}".encode("ascii"))
        # Remember it's a CIFAR_Image object that is loaded
        cifar_image = pickle.loads(data)
        # Retrieve the relevant bits
        image = cifar_image.get_image()
        label = cifar_image.label
    env.close()

    return image, label -->
lalu pada read_single_lmdb sama membaca 1 paramter yang sama kemudian membuka lmdb dengan lmdb dengan menggunakan mode readonly, pada data gambar didekode dan dikonversi menjadi array menggunakan metode get_image() dari objek CIFAR_Image sedangkan labelnya diambil langsung dari objek tersebut.
<!-- def read_single_hdf5(image_id):
    """ Stores a single image to HDF5.
        Parameters:
        ---------------
        image_id    integer unique ID for image

        Returns:
        ----------
        image       image array, (32, 32, 3) to be stored
        label       associated meta data, int label
    """
    # Open the HDF5 file
    file = h5py.File(hdf5_dir / f"{image_id}.h5", "r+")

    image = np.array(file["/image"]).astype("uint8")
    label = int(np.array(file["/meta"]).astype("uint8"))

    return image, label -->
fungsi read_single_hdf5 sama dengan parameter yang sama, kemudian membuka fole hdf5 dengan modul hdf5 untuk membca image dan label dimana data gambar dikonversi menjjadi arry dengan tipe data uint8 sedankan label dengan tipe int.
<!-- _read_single_funcs = dict(
    disk=read_single_disk, lmdb=read_single_lmdb, hdf5=read_single_hdf5
) -->
pada kode ini membuat dictionary untuk eksperimen memvbaca satu gambar dengan nama _read_single_funcs.
<!-- from timeit import timeit

read_single_timings = dict()

for method in ("disk", "lmdb", "hdf5"):
    t = timeit(
        "_read_single_funcs ",
        setup="image=images[0]; label=labels[0]",
        number=1,
        globals=globals(),
    )
    read_single_timings[method] = t
    print(f"Method: {method}, Time usage: {t}") -->
selanjutnya mengukur waktu untuk membaca satu gambar dengan menggunakan timeit pada 2 metode yang telah dibuat seblumnya dengan menyimpan hasilnya kedalam read_single_timings yang hasilnya pada disk lebih cepat membacanya.
## Reading Many Images (Membaca Banyak Gambar)
<!-- def read_many_disk(num_images):
    """ Reads image from disk.
        Parameters:
        ---------------
        num_images   number of images to read

        Returns:
        ----------
        images      images array, (N, 32, 32, 3) to be stored
        labels      associated meta data, int label (N, 1)
    """
    images, labels = [], []

    # Loop over all IDs and read each image in one by one
    for image_id in range(num_images):
        images.append(np.array(Image.open(disk_dir / f"{image_id}.png")))

    with open(disk_dir / f"{num_images}.csv", "r") as csvfile:
        reader = csv.reader(
            csvfile, delimiter=" ", quotechar="|", quoting=csv.QUOTE_MINIMAL
        )
        for row in reader:
            labels.append(int(row[0]))
    return images, labels

def read_many_lmdb(num_images):
    """ Reads image from LMDB.
        Parameters:
        ---------------
        num_images   number of images to read

        Returns:
        ----------
        images      images array, (N, 32, 32, 3) to be stored
        labels      associated meta data, int label (N, 1)
    """
    images, labels = [], []
    env = lmdb.open(str(lmdb_dir / f"{num_images}_lmdb"), readonly=True)

    # Start a new read transaction
    with env.begin() as txn:
        # Read all images in one single transaction, with one lock
        # We could split this up into multiple transactions if needed
        for image_id in range(num_images):
            data = txn.get(f"{image_id:08}".encode("ascii"))
            # Remember that it's a CIFAR_Image object 
            # that is stored as the value
            cifar_image = pickle.loads(data)
            # Retrieve the relevant bits
            images.append(cifar_image.get_image())
            labels.append(cifar_image.label)
    env.close()
    return images, labels

def read_many_hdf5(num_images):
    """ Reads image from HDF5.
        Parameters:
        ---------------
        num_images   number of images to read

        Returns:
        ----------
        images      images array, (N, 32, 32, 3) to be stored
        labels      associated meta data, int label (N, 1)
    """
    images, labels = [], []

    # Open the HDF5 file
    file = h5py.File(hdf5_dir / f"{num_images}_many.h5", "r+")

    images = np.array(file["/images"]).astype("uint8")
    labels = np.array(file["/meta"]).astype("uint8")

    return images, labels

_read_many_funcs = dict(
    disk=read_many_disk, lmdb=read_many_lmdb, hdf5=read_many_hdf5
) -->
pada kode ini sama dengan sinle image, dimana mengginkan paramter yaitu num_imaged dengan 3 metode yang sama yang mana pada fungsi read_many_disk membaca gambar dan labelnya dari file PNG dan CSV di penyimpanan disk lalu read_many_lmdb membaca gambar dan labelnya dari database LMDB kemudian fungsi read_many_hdf5 membaca gambar dan labelnya dari file HDF5 yang selanjutnya disimpan kedalam dictionary _read_many_funcs untuk menghubungkan string dengan fungsi yang sesuai.
<!-- from timeit import timeit

read_many_timings = {"disk": [], "lmdb": [], "hdf5": []}

for cutoff in cutoffs:
    for method in ("disk", "lmdb", "hdf5"):
        t = timeit(
            "_read_many_funcs[method](num_images)",
            setup="num_images=cutoff",
            number=1,
            globals=globals(),
        )
        read_many_timings[method].append(t)

        # Print out the method, cutoff, and elapsed time
        print(f"Method: {method}, No. images: {cutoff}, Time usage: {t}") -->
pada kode diatas mengukur waktu yang diperlukan (timeit) dimana setiap metode dijalankan sekali untuk setiap jumlah gambar yang diproses dalam cutoffs dan hasilnya dicatat dalam dictionaryread_many_timings
<!-- disk_x_r = read_many_timings["disk"]
lmdb_x_r = read_many_timings["lmdb"]
hdf5_x_r = read_many_timings["hdf5"]

plot_with_legend(
    cutoffs,
    [disk_x_r, lmdb_x_r, hdf5_x_r],
    ["PNG files", "LMDB", "HDF5"],
    "Number of images",
    "Seconds to read",
    "Read time",
    log=False,
)

plot_with_legend(
    cutoffs,
    [disk_x_r, lmdb_x_r, hdf5_x_r],
    ["PNG files", "LMDB", "HDF5"],
    "Number of images",
    "Seconds to read",
    "Log read time",
    log=True,
) -->
kode tersbut merupakan untuk menampilkan grafik dari waktu yang sebelumnya, dimana grafik waktu menunjukan perbedaan yang sanagt drastis anatara png, lmbd dan hdf5 dimana, pada log waktu meunjukan oerbedaan jumlah gambar yang lebih sedikit.
